{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "class WordEmbeddingDebiaser:\n",
    "\n",
    "    def __init__(self,\n",
    "                embedding_file_path='GoogleNews-vectors-negative300.bin',\n",
    "                definitional_file_path='definitional_pairs.json',\n",
    "                equalize_file_path='equalize_pairs.json',\n",
    "                gender_specific_file_path='gender_specific_full.json'\n",
    "        ):\n",
    "\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            embedding_file_path, binary=True)\n",
    "\n",
    "        # collect first 300000 words\n",
    "        self.words = sorted([w for w in self.model.vocab],\n",
    "                            key=lambda w: self.model.vocab[w].index)[:300000]\n",
    "\n",
    "        # all vectors in an array (same order as self.words)\n",
    "        self.vecs = np.array([self.model[w] for w in self.words])\n",
    "        tqdm.write('vectors loaded')\n",
    "        # should take 2-5 min depending on your machine\n",
    "\n",
    "        self.n, self.d = self.vecs.shape\n",
    "\n",
    "        # word to index dictionary\n",
    "        self.w2i = {w: i for i, w in enumerate(self.words)}\n",
    "\n",
    "        # Some relevant words sets required for debiasing\n",
    "        with open(definitional_file_path, \"r\") as f:\n",
    "            self.definition_pairs = json.load(f)\n",
    "\n",
    "        with open(equalize_file_path, \"r\") as f:\n",
    "            self.equalize_pairs = json.load(f)\n",
    "\n",
    "        with open(gender_specific_file_path, \"r\") as f:\n",
    "            self.gender_specific_words = json.load(f)\n",
    "        self._normalize()\n",
    "\n",
    "    # Some potentially helpful functions, you don't have to use/implement them.\n",
    "    def accuracy(self):\n",
    "        accuracy = self.model.accuracy('./data/questions-words.txt')\n",
    "    \n",
    "        sum_corr = len(accuracy[-1]['correct'])\n",
    "        sum_incorr = len(accuracy[-1]['incorrect'])\n",
    "        total = sum_corr + sum_incorr\n",
    "        percent = lambda a: a / total * 100\n",
    "        print('Total sentences: {}, Correct: {:.2f}%, Incorrect: {:.2f}%'.format(total, percent(sum_corr), percent(sum_incorr)))\n",
    "\n",
    "    def _normalize(self):\n",
    "        \"\"\"\n",
    "        normalize self.vecs\n",
    "        \"\"\"\n",
    "        self.vecs /= np.linalg.norm(self.vecs, axis=1)[:, np.newaxis]\n",
    "\n",
    "    def _drop(self, u, v):\n",
    "        \"\"\"\n",
    "        remove a direction v from u\n",
    "        \"\"\"\n",
    "        return u - v * u.dot(v) / v.dot(v)\n",
    "\n",
    "    def w2v(self, word):\n",
    "        \"\"\"\n",
    "        for a word, return its corresponding vector\n",
    "        \"\"\"\n",
    "        return self.vecs[self.w2i[word]]\n",
    "\n",
    "    def debias(self):\n",
    "        self.gender_direction = self.identify_gender_subspace()\n",
    "        self.neutralize()\n",
    "        self.equalize()\n",
    "\n",
    "    def identify_gender_subspace(self):\n",
    "        \"\"\"Using self.definitional_pairs to identify a gender axis (1 dimensional).\n",
    "\n",
    "          Output: a gender direction using definitonal pairs\n",
    "\n",
    "        ****Note****\n",
    "\n",
    "         no other unimported packages listed above are allowed, please use\n",
    "         numpy.linalg.svd for PCA\n",
    "\n",
    "        \"\"\"\n",
    "        matrix = []\n",
    "        for a, b in self.definition_pairs:\n",
    "            center = (self.w2v(a) + self.w2v(b)) / 2\n",
    "            matrix.append(self.w2v(a) - center)\n",
    "            matrix.append(self.w2v(b) - center)\n",
    "        matrix = np.array(matrix)\n",
    "        # pca = PCA(n_components=10)\n",
    "        # pca.fit(matrix)\n",
    "        # gender_direction = pca.components_[0]\n",
    "        u, s, v = np.linalg.svd(matrix)\n",
    "        gender_direction = v[0, :]\n",
    "\n",
    "        return gender_direction\n",
    "\n",
    "        # raise NotImplementedError('You need to implement this.')\n",
    "\n",
    "    def neutralize(self):\n",
    "        \"\"\"Performing the neutralizing step: projecting all gender neurtal words away\n",
    "        from the gender direction\n",
    "\n",
    "        No output, please adjust self.vecs\n",
    "\n",
    "        \"\"\"\n",
    "        specific_set = set(self.gender_specific_words)\n",
    "        for i, w in enumerate(self.words):\n",
    "            if w not in specific_set:\n",
    "                self.vecs[i] = self._drop(self.vecs[i], self.gender_direction)\n",
    "        self._normalize()\n",
    "        # raise NotImplementedError('You need to implement this.')\n",
    "\n",
    "    def equalize(self):\n",
    "        \"\"\"Performing the equalizing step: make sure all equalized pairs are\n",
    "        equaldistant to the gender direction.\n",
    "\n",
    "        No output, please adapt self.vecs\n",
    "\n",
    "        \"\"\"\n",
    "        for (a, b) in self.equalize_pairs:\n",
    "            if (a in self.w2i and b in self.w2i):\n",
    "                y = self._drop((self.w2v(a) + self.w2v(b)) / 2,\n",
    "                               self.gender_direction)\n",
    "                z = np.sqrt(1 - np.linalg.norm(y)**2)\n",
    "                if (self.w2v(a) - self.w2v(b)).dot(self.gender_direction) < 0:\n",
    "                    z = -z\n",
    "                self.vecs[self.w2i[a]] = z * self.gender_direction + y\n",
    "                self.vecs[self.w2i[b]] = -z * self.gender_direction + y\n",
    "        self._normalize()\n",
    "        # raise NotImplementedError('You need to implement this.')\n",
    "\n",
    "    def compute_analogy(self, w3, w1='woman', w2='man'):\n",
    "        \"\"\"input: w3, w1, w2, satifying the analogy w1: w2 :: w3 : w4\n",
    "\n",
    "        output: w4(a word string) which is the solution to the analogy (w4 is\n",
    "          constrained to be different from w1, w2 and w3)\n",
    "\n",
    "        \"\"\"\n",
    "        diff = self.w2v(w2) - self.w2v(w1)\n",
    "        vec = diff / np.linalg.norm(diff) + self.w2v(w3)\n",
    "        vec = vec / np.linalg.norm(vec)\n",
    "        if w3 == self.words[np.argsort(vec.dot(self.vecs.T))[-1]]:\n",
    "            return self.words[np.argsort(vec.dot(self.vecs.T))[-2]]\n",
    "        return self.words[np.argmax(vec.dot(self.vecs.T))]\n",
    "    def ret(self):\n",
    "        self.gender_direction = self.identify_gender_subspace() #to get the gender direction before debiasing\n",
    "        #self.debias()        #uncomment it to get debiased word vectors. Comment previous line.\n",
    "        return self.vecs,self.words,self.gender_direction,self.gender_specific_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors loaded\n"
     ]
    }
   ],
   "source": [
    "w = WordEmbeddingDebiaser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs,words,gd,gsw = w.ret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading profession words\n",
    "with open('profession_words.json', \"r\") as f:\n",
    "        pw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing bias before debiasing\n",
    "sprev = []\n",
    "for i in pw:\n",
    "    a = np.dot(w.w2v(i).reshape(1,-1),gd.reshape(-1,1)).flatten()\n",
    "    sprev.append(abs(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08050745"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average bias before debiasing\n",
    "np.array(sprev).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing bias after debiasing\n",
    "snew = []\n",
    "for i in pw:\n",
    "    a = np.dot(w.w2v(i).reshape(1,-1),gd.reshape(-1,1)).flatten()\n",
    "    snew.append(abs(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015350548"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average bias after debiasing\n",
    "np.array(snew).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "snew = np.array(snew)\n",
    "sprev = np.array(sprev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking words with bias higher than or equal to bias before debiasing\n",
    "pw1 = pwarr[snew.flatten()>=sprev.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actress', 'ballerina', 'businessman', 'businesswoman',\n",
       "       'congressman', 'councilman', 'dad', 'handyman', 'housewife',\n",
       "       'maid', 'monk', 'nun', 'salesman', 'socialite', 'statesman',\n",
       "       'teenager', 'waitress'], dtype='<U19')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The 17 words\n",
    "pw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actress\n",
      "ballerina\n",
      "businessman\n",
      "businesswoman\n",
      "congressman\n",
      "councilman\n",
      "dad\n",
      "handyman\n",
      "housewife\n",
      "maid\n",
      "monk\n",
      "nun\n",
      "salesman\n",
      "socialite\n",
      "statesman\n",
      "teenager\n",
      "waitress\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# These 17 words are not part of the gender specific words set\n",
    "c = 0\n",
    "for i in pw:\n",
    "    if i in gsw:\n",
    "        c = c+1 \n",
    "        print(i)\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
